++==============++
|| Apache Kafka ||
++==============++

* Apache kafka is a distributed messaging platform that supports publisher subscriber pattern.
* Initially, kafka was created by LinkedIn for distributed messaging and now, it is under apache foundation and mainly maintained by confluent.

** About Kafka : 
    * It is an open source project.
    * Kafka is distributed, resilient architecture and fault tolerant.
    * Kafka scales horizontaly (adding more machines (clusters)).
    * Kafka can scale to 100s of brokers.
    * It is proven by LinkedIn and many other companies that kafka clusters can scale to millions of messages per second.
    * Kafka is high in performance (Realtime messaging : latency is too low [Less than 10 ms])
    * 35% of Fortune 500 companies uses kafka (such as walmart, LinkedIn, Airbnb, Uber, NETFLIX).

** Use Cases of Kafka : 

    * Messaging System
    * Activity tracking
    * Gather matrics from many different locations (Ex. IoT devices).
    * Application log gathering
    * Stream processing (By Kafka Stream API or Spark)
    * De-coupling system dependencies.
    * Big Data Integrations with Spark, Flink, Storm, Hadoop and many other Big Data technologies.

** Apache Kafka Real world use cases :

    * NETFLIX uses kafka to apply recommendations in real-time while you're watching TV Shows.
    * UBER uses kafka to gather user, taxi, and trip data in real-time to compute and forecast demand, and compute surge pricing in real-time.
    * LinkedIn uses kafka to prevent spam, collect user interactions to make better connection recommendations in real time.

** Kafka Topics : 

    * Topic can be defined as a particular stream of data
    * Similar to table in database.
    * A topic is identified by it's name

** Partitions : Topics are split in Partitions.

    * Each partition is ordered, their index starts from 0 (Like Partition 0, Partition 1, Partition 2,..).
    * Each message within a partition gets an incremental id called offset.
                    +--
                    |  Partition 0 messages : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
                    |
    Kafka Topic :   |  Partition 1 messages : [0, 1, 2, 3, 4, 5, 6, 7, 8, --> writes
                    |
                    |  Partition 2 messages : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10 -->
                    +--
    * While creating kafka topic, we've to specify number of partitions inside it.

** Important notes:

    * Inside the partition, messages will be identified by offset (better to call it offset than index).
    * Offset only have a meaning for a specific partition which means, 3rd offset message of partition 1 has nothing to do with 3rd offset message of partition 2, they could be entirly different.
    * Order of the messages is guranteed only within a partition which means, in partition 1, all the messages are in order based on offset (like offset 6 was written after offset 5 which came after offset 4), but offset 3 of partition 1 and offset 4 of partition 2 has nothing to do with each other, they could be written in different times (not in sequence).
    In the nutshell, order is guranteed only within a partition (not across partitions).
    * In Kafka, data is kept only for a limited time. by default is one week
    * Once the data is written to a partition, it can't be changed (immutability).
    * Values of offsets always keep incrementing for new messages and never goes back to 0.
    * Kafka needs a key, data will be sent randomly to different different partitions of the topic if we don't provide a key (We see this in upcoming practicals).
    * Topics holds partitions. And brokers holds topic.

** Kafka Broker

    * A kafka cluster is composed of multiple brokers (servers).    
    * broker can be Defined as server instance of Kafka.
    * Each broker is identified with its ID which is an integer.
    * Each broker contains certain topic partitions.
    * After connecting to any broker (called bootstrap broker) you will be connected to the entire cluster.
    * A Good number to get started is three brokers, but some big clusters have over 100 brokers.
    * Ex. In these examples we choose to number brokers starting at 100 (arbitrary).
        Broker 101, Broker 102, Broker 103.

    * Kafka Topic will be spread to the different brokers by its partitions.
    * Ex. given the 3 brokers in above example, let's say we have topic-A with 3 partitions (par 0, par 1, par 2).
        +-------------+     +-------------+     +-------------+
        | Broker 101  |     | Broker 102  |     | Broker 103  |
        +-------------+     +-------------+     +-------------+
        |   Topic-A   |     |   Topic-A   |     |   Topic-A   |
        | Partition 0 |     | Partition 1 |     | Partition 2 |
        +-------------+     +-------------+     +-------------+
    * Above example doesn't mean that all the partitions will be spread across brokers in sequence, it could be in any order.
    * When you create a topic, kafka will automatic assign the topic and distribute it across all your brokers.
    * Ex. now, in above example, let's add topic B with 2 partitions.

        +-------------+     +-------------+     +-------------+
        | Broker 101  |     | Broker 102  |     | Broker 103  |
        +-------------+     +-------------+     +-------------+
        |   Topic-A   |     |   Topic-A   |     |   Topic-A   |
        | Partition 0 |     | Partition 1 |     | Partition 2 |
        +-------------+     +-------------+     +-------------+
        |   Topic-B   |     |   Topic-B   |     |             |
        | Partition 0 |     | Partition 1 |     |             |
        +-------------+     +-------------+     +-------------+
        
        * here, topic B has only 2 partitions, so Broker 103 will not contain any data from Topic-B.
        * mentioning again that TopicB:Partition 1 can be assigned to Broker 103, we never know, it is not sequential operation.

** Replication : 

    * When we work with distributed systems, we should have some Replication of the data to recover just in case of machine or cluster's unfortunate crash or failure. So, if we configure replication factor properly, failure of a machine or cluster won't affect the whole distributed system, that data will be available in other machines as a replicated data.
    
    * We have to define replication factor while creating topic.

    * Usually the replication factor is between two and three, two is a bit risky, three is a gold standard.

    * Ex. let's say we have 3 brokers just like previous example and We're creating Topic A with 2 partitions, and replication factor is 2 here.

        +-------------+     +-------------+     +-------------+
        | Broker 101  |     | Broker 102  |     | Broker 103  |
        +-------------+     +-------------+     +-------------+
        |   Topic-A   |     |   Topic-A   |     |   Topic-A   |
        | Partition 0 |     | Partition 1 |     | Partition 1 |
        +-------------+     +-------------+     +-------------+
        |             |     |   Topic-A   |     |             |
        |             |     | Partition 0 |     |             |
        +-------------+     +-------------+     +-------------+

        * Here, as you can see, both the partitions of topic-A are now replicated, so we have atleast one copy of both the partitions available. Topic-A:Partition-0 is on broker 101 and 102, and Topic-A:Partition-1 is on broker 102 and 103.

        * Imagine if Broker 102 dies, we still have our data in other brokers.

        * For the replicated partition, the actual partition which was created originally, it is called leader partition and it's replicated partitions are called ISR (In-Sync Replica). So, there will be always one leader and multiple ISR. 
        
        * Leader partition will always receive and serve the data that is supposed to be available in that partition. other ISRs will just stay in sync with Leader. ISRs will serve the data only incase of leader dies.

        * If a leader Broker dies, then there should be something to elect the new leader to serve the data from replications.

        * That is why zookeeper comes to the picture, kafka can not work without zookeeper, zookeeper has some consensous algoritms implemented in it, these algorithms are supposed to do the leader election. So, it is zookeeper who elect the new leader and zookeeper will the only one who will decide which one will be the new leader and which one will be ISR.

        * In case of leader dies, Kafka should not write the data or read the data until the new leader is elected so the ZooKeeper ensures this by using the Zab consensus protocol to replicate a state machine across all servers in the ensemble. The ensemble uses the Zab protocol to elect a leader, and the ensemble cannot write data until that election is complete.

        * So, again, if leader dies, zookeeper will elect a new leader partition to serve the data from ISRs, and then when the dead leader is again up and running, it'll be in sync with updated data and will try to beome leader again. this is happening for you in the background.

        * In the new Kafka version, instead of storing all server config information in Zookeeper, you can store them as a topic partition inside the Kafka server itself.

        * In the new version of kafka, in its architecture, has recently shifted from ZooKeeper to a quorum-based controller that uses a new consensus protocol called Kafka Raft, shortened as Kraft (pronounced “craft”).


** Setting up kafka (Linux)
* Search for the kafka download in google and download it's latest binary and extract it.
* Put the extracted folder in your installation directory (Like program files in windows, in linux or mac, I prefer to put it in ~/KAFKA/)
* For me, the path was ..  /Users/vrspat/KAFKA/kafka_2.13-3.5.0
* Now, export the environment vars so that our scripts will be available right away.
'''
    export KAFKA_HOME=/Users/vrspat/KAFKA/kafka_2.13-3.5.0

    export KAFKA_CONFIGS=$KAFKA_HOME/config
    export KAFKA_CONFIG=$KAFKA_CONFIGS/server.properties

    export ZOOKEEPER_CONFIGS=$KAFKA_HOME/config
    export ZOOKEEPER_CONFIG=$ZOOKEEPER_CONFIGS/zookeeper.properties
'''
* Now, to start kafka, start the zookeeper first and then start kafka.

- First terminal
    >>> zookeeper-server-start.sh $ZOOKEEPER_CONFIG
- Second (Or another terminal side by side if possible)
    >>> kafka-server-start.sh $KAFKA_CONFIG

* Both the servers should be started.
* check it by the command kafka-topics.sh and it should give some output.
* Also, if you want to change the logs and data dir of kafka and zookeeper, edit thir config by nano $KAFKA_CONFIG and nano $ZOOKEEPER_CONFIG and set the value of dataDir or log.dirs.

* In order to interact with kafka, we have CLI and GUI both the options,
* We'll learn CLI here, for GUI, download this simple kafka tool (Offset Explorer) from https://www.kafkatool.com/download.html

* Let's create a topic.

* Open cmd (new one), follow below lines to understand how to create topic.
* To create a kafka-topic, the required things are topic-name, zookeeper host:port, --create flag, no. of partitions for that topic, replication factor (how many times that topic should be replicated).
* note that, we have only one instance of kafka running, remember, we can not create a kafka topic with replication factor greater than no. of kafka brokers available (or no. of kafka instances are running), because each replication of topic is going to stored inside different broker, So here, we have to use 1 as a replication factor since we have only one broker running.
* Apache Kafka ensures that you can't set replication factor to a number higher than available brokers in a cluster as it doesn't make sense to maintain multiple copies of a message on same broker. 

* For versions before 3.4 : We used to use option --zookeeper and provide zookeeper host and port
    SYNTAX : >> kafka-topics --zookeeper {HOST}:2181 --topic {TOPIC_NAME} --create --partitions {NO_OF_PARTITIONS} --replication-factor {NO_OF_REPLICATINS}

    create first_topic : >> kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --create --partitions 3 --replication-factor 1

* For versions after 3.4 : --zookeeper option is deprecated and no longer being used
                         : Instead, kafka will store all the meta data in itself so we have to provide --bootstrap-server and kafka-host and port.
                         : >>> kafka-topics --bootstrap-server localhost:9092 --topic first-topic --create --partitions 3 --replication-factor 1
                         : So, after this line, everywhere replace --zookeeper and zookeeper host port by --bootstrap-server and kafka host and port if you're using version >= 3.4

* it should show that "Created topic first_topic.".
* let's list all the topics.

SYNTAX : >> kafka-topics --zookeeper {HOST}:2181 --list

HERE   : >> kafka-topics --zookeeper 127.0.0.1:2181 --list

* it'll show first_topic in there because we just created it.

* to check the numbe rof partitions for the topic and other properties of topic, we can simply describe topic.

>> kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --describe

* It'll show the whole description of first_topic with all three partitions, leader, replicas, Isr, replication factor, topic name, topic id etc.
* to delete topic, we can use --delete flag.
* But, note that windows version of kafka has a bug, if you try to delete topic, kafka server will crash. careful!
SYNTAX : >> kafka-topics --zookeeper {host}:2181 --topic {TOPIC_NAME} --delete
>> kafka-topics --zookeeper localhost:2181 --topic first_topic --delete
* to delete topic in windows, go to data dir in root of kafka and in kafka folder, delete topics manually.
* if kafka server crash, may be it won't start again, to restart it properly, stop zookeeper and kafka, then go to data dir of root of kafka, make kafka and zookeeper dirs in there empty, start zookeeper and kafka with same properties files again.

* Kafka Producer : Let's use a kafka CLI producer to produce some messages, note that once producer is started, we can just send messages by writing and pressing enter key, if we want to stop sending messages, we can press Ctrl + C.

SYNTAX : kafka-console-producer --broker-list {KAFKA_HOST}:9092 --topic {KAFKA_TOPIC_NAME}
>> kafka-console-producer --broker-list localhost:9092 --topic first_topic

* now it'll let you send messages like commands, output of mine is below.
>Hello there
>I'm Vrushank kafka 
>Awesome course
>Terminate batch job (Y/N)? y 

* at the end, when i pressed Ctrl + C, it asked to terminate batch job, i pressed Y and it terminated.
* If you havn't faced any error, then consider it as producing messages successfully.

* We just tried producer command which used default properties, we can override some of the properties by passing it with command as below.
* let's override acks property.

SYNCAX : kafka-console-producer --broker-list {KAFKA_HOST}:9092 --topic {KAFKA_TOPIC_NAME} -- producer-property {PROPERTY_KEY}={PROPERTY_VALUE}
>> kafka-console-producer --broker-list localhost:9092 --topic first_topic --producer-property acks=all

* Again, it'll start producer, you can publish the messages but this time, acks will be for all because we've overridden that property.

* Till now, we used producer on the topic we created earlier, but what if we try to produce messages on the topic which doesn't exists, let's try for a topic called new_topic which doesn't exists.

>> kafka-console-producer --broker-list localhost:9092 --topic new_topic

* Surprisingly, it'll let you produce message this time as well, but what happened, topic doesn't exists right?
* But when you send your first message, it'll show you a warning of LEADER_NOT_AVAILABLE because topic didn't existed before, but when you send messages again, they'll pass easily without any warning or error.
* In my case, it went something like given below

>new topic message
[2021-06-29 09:45:16,224] WARN [Producer clientId=console-producer] Error while fetching metadata with correlation id 3 : {new_topic=LEADER_NOT_AVAILABLE} (org.apache.kafka.clients.NetworkClient)
>just saw the warning
>now, there is no warning
>amazing
>Terminate batch job (Y/N)? y

* Now, first of all, try to list all the partitions again, you'll notice that kafka has created new_topic for us it self.

>> kafka-topics --zookeeper 127.0.0.1:2181 --list

* But how, and what properties did it use for this new_topic, let's describe it to find out.

>> kafka-topics --zookeeper 127.0.0.1:2181 --topic new_topic --describe

* As you can see, this new_topic that kafka created was created with 1 partitionCount and 1 ReplicationFactor.
* This is not what we want, because we always want more partitions and replication factors. So, it is always recommended to create a topic before producing messages on it otherwise it'll be created with some defaults which is usually not good.

* Think where did kafka take these default properties from, may be you're right, it is server.properties file, if you want to change this deafults to autocreate partitions with some proper default properties, we can change it in server.properties, so open server.properties (located in config folder of root of kafka) or $KAFKA_CONFIG in your favourite editor.
* change num.partitions value to 3 (OR your specific default value for topic creation)
* Now, stop kafka broker (server instance) and re execute it.
* Now, try to publish messages on topic that doesn't exist, it'll create this topic with 3 partitions (OR your specified num.partitions in server.properties), you can check this by describing topic after publishing messages. do it as an exercise.

* Now, we have published few messages, let's consume them by kafka consumer.
* publish some messages on new_topic because we'll use it here to consume messages.

SYNTAX : >> kafka-console-consumer --bootstrap-server {KAFKA_HOST}:{KAFKA_PORT OR 9092 DEFAULT} --topic {TOPIC_NAME}

>> kafka-console-consumer --bootstrap-server localhost:9092 --topic new_topic

* Now, we've already published 6 to 7 messages on new_topic but this consumer is showing nothing, thats odd.
* Note that by default, the consumer will start consuming the messages that are published only after that consumer is launched.

* Keep consumer there alive running and open another CMD, start producing messages there on new_topic, you'll notice that consumer is consuming and showing all those published messages immediately.
* But, what about messages we published earlier, our consumer missed them, we want to consume all the messages published on the topic so far, for that, we have to start consumer with a flag.
* try below command to start consumer which will consume all the messages published from the beginning.

>> kafka-console-consumer --bootstrap-server localhost:9092 --topic new_topic --from-beginning

* Now, you'll see that consumer has consumed all the messages published from the beginning by publisher on new_topic.

* Now, this new_topic had only one partition, so the messages that consumer consumed were in order as they were published because this topic has one partition only.
* We created first_topic with 3 partitions, if you've deleted it, recreate it with 3 partitions and try to publish 10 messages and keep the order in mind, now start consumer for first_topic with --from-beginning, you'll notice that consumer is consuming all the messages from beginning but not in order, they are consumed randomly, reason of this is first_topic has 3 partitions, and as we've mentioned before that order of the message is guranteed in a partition only, not across multiple partitions, so here, kafka-consumer is consuming messages from 3 partitions so, the consuming messages should be done like consuming all messages from partition 1, then consuming all messages from partition 2, and then consuming all messages from partition 3, note that messages can be stored across multiple partitions randomly, that is why consumer consumes the messages randomly.

* we just created individual consumer, kafka provides facility to group the consumers which means consumers will be grouped and share messages like load balance.
	Ex.. : 
		Consumer group 1 : Member 1	<----message 1----+--------------+
		Consumer group 1 : Member 2	<----message 2----+ Kafka topics |
		Consumer group 1 : Member 3	<----message 3----+--------------+
* As you can see, members of same consumer group retrieve the messages of the topic in a way that all the messages will be delivered across the members, So if member 1 is getting message 1, then message 2 will be delivered to member 2 and message 3 to member 3. So, messages will be distributed across all the members of consumer group (In short, the same message will not delivered to multiple members of same consumer group).

* If we add member, the messages will be distributed to the new number of members of consumer group, and if we stop or remove anu member of consumer group, then upcoming messages will be distributed across new number of members again.

* Enough theory, let's try to run multiple consumers of a consumer group as my_first_consumer_group.

* Open CMD..

SYNTAX : >> kafka-console-consumer --bootstrap-server {KAFKA_HOST}:9092 --topic {TOPIC_NAME} --group {GROUP_NAME}
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_first_consumer_group

* Open another CMD.
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_first_consumer_group

* Open another CMD.
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_first_consumer_group

* Now, we have three consumers of same consumer group as my_first_consumer_group, open another CMD and start producing messages.
>> kafka-console-producer --broker-list localhost:9092 --topic first_topic  

* start producing messages one by one and notice in other three consumers of my_first_consumer_group, you'll notice that messages are being distributed across all three consumers, not uniformly ofcourse, but getting distributed.

* Here, using consumer with consumer-group and without consumer-group has a huge difference, let me show you.
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --from-beginning
* above command runs consumer without any group and consume messages from beginning, no matter how many times you run above command, it'll consume all the messages from beginning every time, now let's try the same consumer with --from-beginning with consumer group.
* Stop all the consumers and producers, run a producer of first_topic and publish 10 to 20 messages.
* Now, try below consumer from new group my_second_consumer_group with --from-beginning
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_second_consumer_group --from-beginning

* You'll see the consumer is consuming all the messages from beginning and showing, now press Ctrl + C and stop it, and re execute same command again, you'll notice it is not consuming the old messages, now, it'll start consuming messages from the last message it read, all the messages read before will be ignored.

* stop all consumers and producers and run producer on first_topic again, and publish 10 to 20 messages again.
* not open three CMDs and run consumers for first_topic with group my_second_consumer_group with --from-beginning.
* you'll notice that the consumer opened first time is reading all the messages from beginning, others are not because those messages are considered already read by that group my_second_consumer_group.
* all these things are happening because of offsets because kafka stores the offset of last message read by group of consumers and then continue delivering messages from last read message only, that is the importance of offset. zookeeper is responsible for storing this offset value to continue delivery from last message read by group for consumers.

* In the nutshell, use --from-beginning with consumer group, it'll read all the messages from beginning once only no matter how many times you run that command with that same consumer group only. but without consumer group, it'll read messages from beginning every time you run the command.

* what if we want to read from beginning again for same consumer-group, for that we need to reset the offset for that consumer group.

* Good thing to notice is there is no separate mechanism for creating groups, just use it, kafka will create it for you.
* We can list all the consumer groups in kafka by below command.
SYNTAX : kafka-consumer-groups --bootstrap-server {KAFKA_HOST}:9092 --list 
>> kafka-consumer-groups --bootstrap-server localhost:9092 --list 

* We can describe the kafka group to find out CURRENT READ OFFSET, PARTITIONS, LOG END OFFSET, TOPIC NAME for each partitions.
SYNTAX : kafka-consumer-groups --bootstrap-server {KAFKA_HOST}:9092 --describe --group {GROUP_NAME}
>> kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group my_first_consumer_group

O/P : 
--------------------------------------------------------------------------------------------------------
Consumer group 'my_first_consumer_group' has no active members.

GROUP                   TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
my_first_consumer_group first_topic     0          46              46              0               -               -               -
my_first_consumer_group first_topic     1          58              58              0               -               -               -
my_first_consumer_group first_topic     2          27              27              0               -               -               -
--------------------------------------------------------------------------------------------------------
* in this description, LAG will show the messages LAG for that group which means, the sum of values of LAG column is the number of messages pending for that consumer-group to read.
* consume those messages by that consumer group and describe group again, you'll notice LAG is 0 now.

* check the CONSUMER-ID, HOST AND CLI columns, they're just dashed, because this consumer group is not live.
* open another CMD and run this consumer group my_first_consumer_group.

>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_first_consumer_group

* after running above command, on old cmd, try to describe topic again, you'll notice that we have active members now and they've CONSUMER-ID, HOSt and CLIENT-ID.

>> kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group my_first_consumer_group

O/P : 
-----------------------------------------------------------------------------------------------------
GROUP                   TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID                                                             HOST            CLIENT-ID
my_first_consumer_group first_topic     0          46              46              0               consumer-my_first_consumer_group-1-c5c10746-c16c-4948-85e2-e690da64da30 /192.168.0.105  consumer-my_first_consumer_group-1
my_first_consumer_group first_topic     1          58              58              0               consumer-my_first_consumer_group-1-c5c10746-c16c-4948-85e2-e690da64da30 /192.168.0.105  consumer-my_first_consumer_group-1
my_first_consumer_group first_topic     2          27              27              0               consumer-my_first_consumer_group-1-c5c10746-c16c-4948-85e2-e690da64da30 /192.168.0.105  consumer-my_first_consumer_group-1
-----------------------------------------------------------------------------------------------------

* To describe all the groups and topics, use command below...

>>  kafka-consumer-groups --bootstrap-server localhost:9092 --describe --all-groups --all-topics   

* now, what if we want to reset the offset for a group to read all the messages truly from beginning no matter if they're already read before by the same group or not, for that, we have to reset the offset values.
* before resetting offsets, consume all the messages from first_topic in group my_first_consumer_group to ensure that all the messages are consumed and it is continuing from where left off, we'll reset offset after that to check lag.

* first let's consume all the messages for my_first_consumer_group.
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_first_consumer_group

* now, describe the group my_first_consumer_group by below command to check LAG column to see if any of the message is pending for consumption for that group, we should see 0 over there in LAG column in all rows.
>> kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group my_first_consumer_group
* See, the LAG is 0 means all the messages are consumed well and nothing is pending.
* In my case..
O/P
--------------------------------------------------------------------------------------------------------------
Consumer group 'my_first_consumer_group' has no active members.

GROUP                   TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
my_first_consumer_group first_topic     0          46              46              0               -               -               -
my_first_consumer_group first_topic     1          58              58              0               -               -               -
my_first_consumer_group first_topic     2          27              27              0               -               -               -
--------------------------------------------------------------------------------------------------------------

* Now, let's reset the offsets.
>> kafka-consumer-groups --bootstrap-server localhost:9092 --group my_first_consumer_group --reset-offsets --to-earliest --execute --topic first_topic
* --to-earliest means to the very beginning of the messages, so the offsets will be 0 and we can consume messages fromvery first message.

* Now, describe the group my_first_consumer_group again, you should see values in LAG, it should show all the pending number of messages.
>> kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group my_first_consumer_group
* It should show you the values in LAG, in my case, check below.
O/P
--------------------------------------------------------------------------------------------------------------
Consumer group 'my_first_consumer_group' has no active members.
GROUP                   TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
my_first_consumer_group first_topic     0          0               46              46              -               -               -
my_first_consumer_group first_topic     1          0               58              58              -               -               -
my_first_consumer_group first_topic     2          0               27              27              -               -               -
--------------------------------------------------------------------------------------------------------------

* now, try to consume the message for group my_first_consumer_group from beginning.
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_first_consumer_group
* It'll consume all the messages from very beginning.

* while resetting offsets, we used --topic and specified topic, but if you want to reset offsets for all the topics for that group, then you can do it by using --all-topics instead of --topic and specifying topic with --topic.
* Like below...
>> kafka-consumer-groups --bootstrap-server localhost:9092 --group my_first_consumer_group --reset-offsets --to-earliest --execute --all-topics

* We used --to-earliest to reset to very begining, we have other options too.
* let's move the offsets 3 step backwards to read last 3 messages that is already consumed.
>> kafka-consumer-groups --bootstrap-server localhost:9092 --group my_first_consumer_group --reset-offsets --shift-by -3 --execute --topic first_topic
* -3 means 3 steps backwards and of we write 3, that means 3 steps forward, - is necessary to represent backwards.

* Now, if you describe that group my_first_consumer_group, you can see LAG column should show you 3 because offsets are shifted to 3 steps backwards.
>> kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group my_first_consumer_group
O/P
-------------------------------------------------------------------------------------------------------------
Consumer group 'my_first_consumer_group' has no active members.

GROUP                   TOPIC           PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG             CONSUMER-ID     HOST            CLIENT-ID
my_first_consumer_group first_topic     0          43              46              3               -               -               -
my_first_consumer_group first_topic     1          55              58              3               -               -               -
my_first_consumer_group first_topic     2          24              27              3               -               -               -
-------------------------------------------------------------------------------------------------------------

# Now, we'll try to use Producer and Consumer from Java program, so checkout kafka-first-demo project in root of this dir.

# Also, don't forget to try twitter producer-consumer in the same project.

# Let's discuss more about some of the important properties of producer (kafka producer).
# ack : Acknowledgement 
# ack is like a response from kafka broker that says that hey producer, i've got the message that you just produced.
# ack property can have 3 values
# default value of ack = 1
# 1) ack = 0
# :: This means that once producer produces message to broker, broker should save it or process it but no need to respond to producer, producer will consider it like success. now, if the broker is down and producer produces message, producer will never know if the message is published or not because ack = 0 means no Acknowledgement is required from broker. so, producer will never know that the message is published to broker or replications or not.
This can cause a data loss, but at the sametime, this ack is useful in some scenarios.
For log processing, if one or two lines of log is not published through pipeline, it's not end of the world, it is okay to loose once a 100 logs or something, we can afford that, so in that kind of scenarios, we can use ack = 0 or in each scenarios where we can afford data loss, we can use ack = 0.

# 2) ack = 1 (producer will get ack once leader broker get the published message)
# :: This means that once producer produces the message to leader broker, once leader broker get that it'll send response (acknowledgement) immediately back to producer that "Hey, i've got your message, here is the ack and I'll store it to disk and to the in sync replicas as well". So, producer will understand it like a success and communication will be over.
If, the leader broker is not available then one of the ISR(in-sync-replica) will become leader and it'll do the same process, but if the whole cluster is down, then no ack will be sent to producer, so after some timeOut, producer will publish the msssage again because it is it's responsibility to publish this message successfully to broker.
Now here, the problem is, leader broker is storing the message to ISR (in-sync-replicas) brokers after sending the ack to producer.
What if any of the ISR is unavailable (like dead ot crashed), that replication will fail. but the good thing is, that message will still be available in the leader broker. But, if leader broker die or crash in the future, we might face a loss of data. this type of ack value is atleast better than ack = 0.

# 3) ack = all (producer will get the acknowledgement once all the ISRs and Leader get the message)
# when you set acks = all, kakfa will consider it as integer value -1 (negative 1).
# :: this means that once producer produces the message, leader will get that message and will store it to all the In-Sync-Replicas at the same time, all the replicas will store the message and acknowledge back to leader that "we've got the message", if leader get the ack from all the ISRs, it'll send acknowledgement to producer that message is stored successfully.
Now here, what if replication factor is 3 and only 2 ISRs are available, in that case, leader will know that enough replications are not done, so, it'll send Exception as NOT_ENOUGH_REPLICAS, so, the producer will try again after a specific timeOut to fullfill it's responsibility.
Here, assume that we can have more than 10 brokers or more. in that case, all the ISRs need to ack back to leader. this will slow down the process so, we can provide another property min.insync.replicas to producer that will define the least number of In-Sync_Replica needs to ack back to leader, so leader will not expect all the ISRs to store message and ack but it'll expect only the number (property defined for min.insync.replicas) of ISRs to be insync with leader.
let's say we have 3 brokers and 3 is replication factor and we are setting min.insync.replicas = 2.
Now, if producer sends message to Leader broker, leader broker will try to store it to ISRs, since min.insync.replicas = 2, leader will send ack to producer immediately once it gets ack from 2 ISRs. which means, ack will be sent until 1 ISR is down, if more than 1 ISR is down, then replication factor 2 will not fullfill and broker will send NOT_ENOUGH_REPLICAS as exception.
ack = all will cause increased latency but improced safety at the same time.

Remember, it is role of producer to perform retries until the write succeeds.

There is a setting of "retries"
which defines number of retries producer needs to perform incase of message publishing failure.
default value of retries =  0;
we can change it to retries = Integer.MAX_VALUE
If we rely on key based ordering, there could be an issue, because we don't have gurantee that all the same keys will go in order to the same partition. they may go to the same partition but they may not be in order anymore.
to handle this, we have a setting of max.in.flight.requests.per.connection
remember, flight means number of messages we producer can producer at the same time, if it is 5, then 5 messages can be produced at the same time and other will be batched after those 5.
max.in.flight.requests.per.connection's default value is 5, but we have to set it to 1 if we want to ensure the ordering of messages but that may impact the throughput.
If you use kafka version > 1.0.0, there is a better solution available given below, otherwize use setting max.in.flight.requests.per.connection = 1 only.

Idempotent producer:
In kafka, once producer produces message to broker, broker save the message to partition and  will acknowledge back, but it is possible that due to some network error, this acknowledge will never make it to producer back, so, after some timeOut, producer will produce the same message again and broker will commit the message to partition, this will cause duplicates of the messages, to solve this issue, we have Idempotent producer.

for kafka version >0.11, there is a feature of request_id, so when producer will send message to broker, that request and it's retries requests will have a request_id, so if broker can not acknowledge back, producer will republish the same message with same request_id, this time, broker will check this request_id and immediately understand this is the duplicate message, so it'll not commit it twice, instead, it'll try to acknowledge backto producer, so the duplication will not occur anymore.

Idempotent producers are great to gurantee a stable and safe pipeline.
Idempotent producers comes with 
    retries = Integer.MAX_VALUE (2147483647)
    max.in.flight.requests = 1 (Kafka >=0.11 & <1.1) or
    max.in.flight.requests = 5 (Kafka >= 1.1 - Higher Performance)
    acks = all (Ensure not loose data)

To use Idempotent producer, just set below property in java kafka producer configuration.
    producerProps.put("enable.idempotence", true)
Idempotent producer is kind of safe producer as well, remember, safe producer may impact the latency and throughput but check the latency and throughput, if it is good enough for you, go for it other think about better option if available.

Compression in Kafka:
Usually we send JSON format data in kafka, JSON is actually nothing but a text format which can have many line breaks and spaces, and a plain text can be very heavy in size.
in this case, it is very important to apply compression to data.
In kafka, compression is something that happens at the producer level so, no change is required at broker or consumer level.
just like earlier, we have to set a setting, and everything will be taken care of.
Just set compression.type to any of given values which shows different compression values.
    * none (default)
    * gzip (slow but high compression)
    * lz4
    * snappy
Compression is effective the bigger the batch of messages being sent to kafka.
Compression will reduce the size and it'll be soo easy for broker to store that decreased sized compressed data, also, storage can be used effeciently because of reduced size and time taken for consumer to consume data will be less (definetely it'll decompress the data).

Advantages : 
    The Compressed batch has much smaller producer request site (compression ratio up to 4x).
    Faster to transfer data over network (less latency)
    Better throughput
    better disk utilization (stored messages are smaller so easy to replicate as well)

Disadvantage : 
    Producer must commit some CPU cycles for compression
    Consumer must commit some CPU cycles for decompression

Overall : 
    Consider testing snappy or lz4 for optimal speed / compression ratio.
    GZip has highest compression ratio.
Test all the compression and decide, or you can have your own compression that you can use and then can pass the compress data directly to producer.
Recommendation : Find a compression algorithm that gives you the best performance for your specific data. Test all of them.
Always use compression in production and especially if you have high throughput.

By default, kafka try to send messages ASAP,
It'll have upto 5 messages at a time, meaning 5 messages individually sent at a time.
After this, if more messages have to be sent while others are in flight, kafka is smart and will start batching them while they wait to send them all at once.
This smart batching allows kafka to increase throughput while maintaining a very low latency.
if we send 1000 messages at once, kafka will batch it for us in the background.
to handle batching, again, we have some kafka settings configuration.

Linger.ms : Number of milliseconds a producer is willing to wait before sending a batch out. (default 0)
By introducing some lag (for example linger.ms = 5), we increase the chances of messages being sent together in a batch.
So, At the expense of introducing the small delay, we can increase throughput, compression and efficiency of our producer.
In the nutshell, if linger.ms = 5, kafka will wait till 5 seconds and will batch all the messages coming up in those 5 seconds, then it'll send that batch.
If a batch is full (see batch.size) before the end of linger.ms period, it'll be sent to kafka right away.
So, Kafka will stop batching and bath will be sent away in two conditions.
    * timeout of linger.ms
    * batch size is full
Also, after timeout or full batch size, the batch will be compressed if compression is enabled (important, sompressed messages will not batched but messages will batched and then batch will be compressed).

batch.size is configuration setting which shows maximum size of messages to be batched and it has a default value 16KB.
Increasing the batch size to something like 32 KB or 64 KB can help increasing the compression, throughput, and efficiency of requests.
Any message that has bigger size than the batch.size will not be batched.
A batch is allocated for partition, so make sure that you don't set it to a number that's too high, otherwise you'll run waste of memory.
default (16 KB) or double (32 KB) or quadruple (64 KB) is fine.
You can monitor the average batch size metric using Kafka producer metrics.

Hashing of keys : Kafka uses murmur2 algorithm to hash the keys.
The formula is : 
    targetPartition = Utils.abs(Utils.murmur2(record.key())) % numPartitions
This means the same key will always go to same partition (we know this already).
Adding partition to a topic will completely alter the formula.

Sometimes, the high throughput producer sends data faster than the broker can handle.
In that scenario, if the broker is overloaded, kafka will store upcoming data in buffer.
Buffer's size is 32MB.
Buffer will fill up until the broker is overloaded and will fill down when the broker will start accepting the messages with high throughput.
Now, what if broker is slow and buffer gets overloaded. in that case, the upcoming produced messages will have to wait.
So, if the buffer is full, the send() method will start blocking the upcoming messages (won't return right away).
till when the messages will be blocked, well, only for 60 seconds.
send method will block the messages until 60 seconds, if buffer gets some space, then send will push the message.
but if 60 seconds timeout passes, then send method will give exception back.
This exception will be thrown when
    * The producer has filled up it's buffer
    * The broker is not accepting any new data
    * 60 seconds are elapsed
the setting of configuration that set this value of timeout to 60 seconds is max.block.ms.
by default, max.block.ms = 60000 ms.

Where other buses and queues have push model, kafka provides poll model to consumer.
This allows consumer to decide where in the log they want to consume, how fast, and gives them ability to replay events.

Here is how poll works..
poll() --------------------- request ---------------------> Broker
poll() <---return data immediately or empty of timedOut --- Broker

We have several more consumer settings to control consumer poll request.
1) Fetch.min.bytes (default 1 byte)
  * Controls how much data you want to pull at least on each request
  * that means that if min.bytes = 10 then we can tell consumer that only consume the data if atleast 10 bytes of data is produced or more.
  * helps improving throughput and decreasing number of requests.
  * at the cost of latency.

2) Max.poll.records (default 500)
  * Controls how many records to receive per poll request.
  * increase that if your messages are very small and have a lot of available RAM and want to consume a lot of messages at the same time.
  
3) Max.partitions.fetch.bytes (default 1 MB)
  * Maximum data returned by the broker per partition.
  * If you read from 100 partitions, you'll need a lot of memory (RAM).

4) Fetch.max.bytes (default 50 MB)
  * Maximum data returned for each fetch request (covers multiple partitions)
  * The consumer performs multiple fetches in parallel.

* Change these settings only if your consumer maxes out the on throughput already. Otherwise, no need to touch them.

We know that consumer commits offsets automatically by default, but we can change that.
Let's see both the strategies.
1) (Easy) enable.auto.commit = true & synchrons processing of batches
So, in here, the offsets will be commited first and then we'll process data.
Here, offsets will be commited automatically for you at regular interval (auto.commit.interval.ms = 5000 by default)
meaning that every 5 seconds by default every time you call poll().
this is okay for synchronus processing but if you do something asynchronus processing with data, you'll be in "at-most-once" behaviour because offsets will be commited before your data is processed.
that is why enable.auto.commit = true can be risky sometimes for beginners.

2) (Medium) enable.auto.commit = false & manual commits of offsets.
In this scenario, we'll set enable.auto.commit = false 
and once we finish all the synchronus operations, 
we'll commit the offsets manually by consumer.commitSync() which make explicit commit happen.
so, in this scenario, you control when you commit offsets and what's the condition for commiting them.
Example : accumulating records into a buffer and then flushing the buffer to a database + commiting offsets then.

* In kafka CLI, to reset the offsets (current offsets) of a consumer group for a particular topic, use below command.
>> kafka-consumer-groups --bootstrap-server {HOST}:{PORT} --group {GROUP_NAME} --reset-offsets --execute --to-earliest --topic {TOPIC_NAME}

# Consumer Threads.
How consumer group works, well consumers groups have two threads, one is for poll thread to poll to Broker and one for heartbeat thread to send a heartbeat to consumer cordinator.
We know poll, but heartbeat, it is a special kind of request that says, "hey, i'm alive" and consumer cordinator will keep it in consumer group registry (similar to service registry).
If any consumer group is not sending heartbeat to cordinator, cordinator will consider that consumer group dead and will rebalance.

There is a configuration..
Session.timrout.ms (default 10 seconds)
this conf var defines how much time should cordinator wait for consumer group to sent heartbeat, after this timeout, it'll consider the consumer group dead.

Another configuration..
Heartbeat.interval.ms (default 3 seconds)
this conf var defines the interval between two heart beats from consumer group.
So, it says that by default, consumer group should send heartbeat every 3 seconds.
We usually set this var to 1/3 of Session.timeout.ms

One more configuration..
max.poll.interval.ms (default 5 minutes)
it defines Maximum amount of time between two poll() calls before declaring consumer dead.
This is particularly relevent for Big Data frameworks like spark incase of processing takes time.

Kafka connect and kafka streams
Till now, if you've already looked at the projects, we've done everything by ourselves.
But there are APIs available that provide boilerplate stuff.
Kafka connect and streams are all about that.
from now on, we'll just consume apis of kafka to interact with it.
we could have different source and target of data pipe line.
some of examples are given below and also which API to use.

Source -> Kafka   : Producer API : We'll use Kafka Connect Source API from now.
Kafka -> Kafka : Consumer, Producer API : We'll use Kafka Streams from now on.
Kafka -> Sink : Consumer API : We'll use kafka connect sink.
Kafka -> App : Consumer API : We'll use kafka connect sink.

Kafka connect and streams simplify and improve getting data in and out of kafka.
Also, it simplify transforming data within kafka without relying on external libs.

Programmer's source of the data can be anything like Database, JDBC, Couchbase, GoldenGate, SAP HANA, BlockChain, Cassandra, DynamoDB, FTP, IOT, MongoDB, MQTT, RethinkDB, Salesforce, Solr, SQS, Twitter etc.
Programmers usually want to store these data into S3, ElasticSearch, HDFS, JDBC, SAP HANA, DocumentDB, Cassandra, DynamoDB, HBase, MongoDB, Redis, Solr, Splunk, Twitter.
It is tough to achieve fault tolerance, idempotence, Distribution and Ordering.
Some programmers who is very good at this job has already done this for us in kafka connect and streams.
Kafka connect is mostly used on ETL pipelines and it scales really well.
Code is really reusable.




=======

Sure, here are some examples of how to use the Kafka CLI commands:

- **kafka-topics**: To create a topic named "test" with 3 partitions and a replication factor of 2, run:

  ```bash
  kafka-topics --create --topic test --partitions 3 --replication-factor 2 --bootstrap-server localhost:9092
  ```

  To list all the topics in Kafka, run:

  ```bash
  kafka-topics --list --bootstrap-server localhost:9092
  ```

  To describe the details of the topic "test", run:

  ```bash
  kafka-topics --describe --topic test --bootstrap-server localhost:9092
  ```

  To delete the topic "test", run:

  ```bash
  kafka-topics --delete --topic test --bootstrap-server localhost:9092
  ```

- **kafka-console-producer**: To write events to the topic "test" from the console, run:

  ```bash
  kafka-console-producer --topic test --bootstrap-server localhost:9092
  ```

  Then type each event in a new line and press enter. To exit, press Ctrl+C.

  To write events to the topic "test" with keys and partitions, run:

  ```bash
  kafka-console-producer --topic test --property parse.key=true --property key.separator=, --property partitioner.class=org.apache.kafka.clients.producer.internals.DefaultPartitioner --bootstrap-server localhost:9092
  ```

  Then type each event in the format of "key,value" and press enter. The partitioner class will assign the events to partitions based on the hash of the keys.

  To write events to the topic "test" from a file named "events.txt", run:

  ```bash
  kafka-console-producer --topic test --bootstrap-server localhost:9092 < events.txt
  ```

- **kafka-console-consumer**: To read events from the topic "test" and print them to the console, run:

  ```bash
  kafka-console-consumer --topic test --bootstrap-server localhost:9092
  ```

  To read events from the earliest offset of the topic "test", run:

  ```bash
  kafka-console-consumer --topic test --from-beginning --bootstrap-server localhost:9092
  ```

  To read events from a specific partition and offset of the topic "test", run:

  ```bash
  kafka-console-consumer --topic test --partition 0 --offset 10 --bootstrap-server localhost:9092
  ```

  To read events from the topic "test" as part of a consumer group named "group1", run:

  ```bash
  kafka-console-consumer --topic test --group group1 --bootstrap-server localhost:9092
  ```

- **kafka-consumer-groups**: To list all the consumer groups in Kafka, run:

```bash
kafka-consumer-groups --list --bootstrap-server localhost:9092
```

To describe the details of the consumer group "group1", run:

```bash
kafka-consumer-groups --describe --group group1 --bootstrap-server localhost:9092
```

To delete the consumer group "group1", run:

```bash
kafka-consumer-groups --delete --group group1 --bootstrap-server localhost:9092
```

To reset the offset of the consumer group "group1" to the earliest offset for all partitions, run:

```bash
kafka-consumer-groups --reset-offsets --to-earliest --all-topics --execute --group group1--bootstrap-server localhost:9092
```

================ChearSheet-101=====================
# to start kafka-server [KAFKA_CONFIG is path to server.properties]
>> kafka-server-start.sh $KAFKA_CONFIG

# to create kafka topic
>> kafka-topics --zookeeper {HOST}:2181 --topic {TOPIC_NAME} --create --partitions {NO_OF_PARTITIONS} --replication-factor {NO_OF_REPLICATINS}
>> kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --create --partitions 3 --replication-factor 1
OR for new kafka versions
>> kafka-topics.sh --bootstrap-server localhost:9092 --topic first-topic --create --partitions 3 --replication-factor 1

# To list all the topics
>> kafka-topics --zookeeper 127.0.0.1:2181 --list
OR for new kafka versions
>> kafka-topics.sh --bootstrap-server localhost:9092 --list

# to describe a topic
>> kafka-topics --zookeeper 127.0.0.1:2181 --topic first_topic --describe
OR for new kafka versions
>> kafka-topics.sh --bootstrap-server localhost:9092 --topic first-
topic --describe

>> kafka-topics --zookeeper {host}:2181 --topic {TOPIC_NAME} --delete
>> kafka-topics --zookeeper localhost:2181 --topic first_topic --delete
OR for new kafka versions
>> kafka-topics --bootstrap-server localhost:9092 --topic first_topic --delete

# To start producer on given brokers 
>> kafka-console-producer --broker-list localhost:9092 --topic first_topic

# Kafka producer requires a lot more configs to pass but the configs we don't pass will be taken default value from server.properties so we can modify it there if we want and restart the kafka broker.
# Also, the producer properties can be overridden during passing the command by --producer-property as given below
>> kafka-console-producer --broker-list localhost:9092 --topic first_topic --producer-property acks=all

# If we use topic that doesn't exist then kafka will create a new topic for us
>> kafka-console-producer --broker-list localhost:9092 --topic new_topic
# See, we can publish messages still, describe the topic to see the default conf kafka took to create this topic
>> kafka-topics.sh  --bootstrap-server localhost:9092 --topic first-topic --describe
# It has created a topic with 1 partition and 1 replication factor and these properties are taken froms server.properties that we pass for kafka to start in the beginning, modify it to take different default properties.

# To list all the topics
>> kafka-topics --zookeeper 127.0.0.1:2181 --list
OR for new kafka versions
>> kafka-topics.sh --bootstrap-server localhost:9092 --list

>> kafka-topics --zookeeper 127.0.0.1:2181 --topic new_topic --describe

# to consume messages on a topic
>> kafka-console-consumer --bootstrap-server {KAFKA_HOST}:{KAFKA_PORT OR 9092 DEFAULT} --topic {TOPIC_NAME}
# Below is to start consumer but it'll consume the messages produced right after it has started, not the earlier produced
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic new_topic
# To consume all the messages produced on the topic since the beginning, try below command with --from-beginning
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic new_topic --from-beginning

# Till now, our consumer was consuming all the messages from the topics.
# if we want to create multiple consumers with grouping them so that they can consume messages by balancing load between, we can do that by grouping so if there are 30 messages in the topic and we start 3 consumers on same group, 10 messages will be consumed by 1 consumer, another 10 will be by 2nd consumer and remaining 10 will be consumed by 3rd one (This is just to say, not necessary that that's how the load will be balanced). Try below command to group the consumers.
>> kafka-console-consumer --bootstrap-server {KAFKA_HOST}:9092 --topic {TOPIC_NAME} --group {GROUP_NAME}
# Below are three consumer start commands from same group, try them in different 3 terminals.
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_first_consumer_group
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_first_consumer_group
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_first_consumer_group

# Start producing messages
>> kafka-console-producer --broker-list localhost:9092 --topic first_topic  

# try another consumer withoug any group with from-beginning.
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --from-beginning

# let's group consumer with my_second_consumer_group byt this time, i want them to consume messages from beginning so below is the command to do that.
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_second_consumer_group --from-beginning

# To list the groups
>> kafka-consumer-groups --bootstrap-server localhost:9092 --list 

# to describe the group's offset of consumers, lag between currently produced messages and consumed messages, below is the command.
>> kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group my_first_consumer_group
# Now, if there is a LAG greater than zero, let's consume messages.
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_first_consumer_group
# Now describe again, the LAG should be zero
>> kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group my_first_consumer_group

# now, let's say our consumer group has consumed all the messages but we want it to start consuming all the messages from beginning again, we can reset it's offsets for a particular topic by below command.
>> kafka-consumer-groups --bootstrap-server localhost:9092 --group my_first_consumer_group --reset-offsets --to-earliest --execute --topic first_topic
# --reset-offsets reset the offsets, --at-earliest set it to 0th offset so from beginning.

# Now, describe the group, you'll see the LAG is same as produced number of messages because we have resetted the offset so they all need to be consumed again.
>> kafka-consumer-groups --bootstrap-server localhost:9092 --describe --group my_first_consumer_group

# consume again and describe the group.
>> kafka-console-consumer --bootstrap-server localhost:9092 --topic first_topic --group my_first_consumer_group

# to reset the offsets of the consumer group for all the topics across kafka, try below with --all-topics rather than specifying topic.
>> kafka-consumer-groups --bootstrap-server localhost:9092 --group my_first_consumer_group --reset-offsets --to-earliest --execute --all-topics
# Exercise :  Now try consuming and describe it again.

# If we want to specifically shift our offset to behind like 3 to 4 offset backwards, we can do that rather than resetting it to beginning. try below command.
>> kafka-consumer-groups --bootstrap-server localhost:9092 --group my_first_consumer_group --reset-offsets --shift-by -3 --execute --topic first_topic
# shift-by 3 will take the offsets to 3 step backwards so now when you start consuming messages, it'll read last 3 consumed messages again.
# Exercise :  Now try consuming and describe it again.
# Exercise : Try resetting the offset and to-earliest/shift-by and all-topics/specific-topic. All these three, try with each other and keep describing group to track everything.
============END-ChearSheet-101=====================